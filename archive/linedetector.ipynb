{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, Javascript, Image\n",
    "\n",
    "from base64 import b64decode, b64encode\n",
    "import PIL\n",
    "import io\n",
    "import html\n",
    "import time\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a video capture object edit the number to find the webcam\n",
    "vid = cv2.VideoCapture(2) \n",
    "# whiteboard = cv2.imread('./Sidewalks/whiteboxcomputer.png', cv2.IMREAD_UNCHANGED)\n",
    "white_image = np.ones((1080, 1920, 3), np.uint8) * 256 \n",
    "  \n",
    "while(True): \n",
    "    whiteboard = np.ones((1080, 1920, 3), np.uint8) * 256 \n",
    "    # Capture the video frame \n",
    "    # by frame \n",
    "    ret, image = vid.read()\n",
    "    y = image.shape[0]\n",
    "    x = image.shape[1]\n",
    "    halfx = int(x/2)\n",
    "    yless = y - 1\n",
    "\n",
    "    # Read the Image\n",
    "    \n",
    "    # Convert BGR image to HSV\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Splitting the HSV image into its components\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    # Define lower and upper thresholds for value segmentation\n",
    "    lower_value_threshold = 0\n",
    "    upper_value_threshold = 150 \n",
    "\n",
    "    # Define lower and upper thresholds for value segmentation\n",
    "    lower_hue_threshold = 30\n",
    "    upper_hue_threshold = 90 \n",
    "\n",
    "    # Create a binary mask based on value thresholds\n",
    "    value_mask = cv2.inRange(v, lower_value_threshold, upper_value_threshold)\n",
    "\n",
    "    # Create a binary mask based on hue thresholds\n",
    "    hue_mask = cv2.inRange(h, lower_hue_threshold, upper_hue_threshold)\n",
    "\n",
    "    # Combine the value and hue mask\n",
    "    composite_mask = cv2.bitwise_and(value_mask, hue_mask)\n",
    "\n",
    "    # Apply the mask to the original image to remove shadows\n",
    "    segmented_image = cv2.bitwise_and(image, image, mask=composite_mask) \n",
    "\n",
    "    # Convert Image to Grayscale\n",
    "    img_gry = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Equalize the contrast of the image\n",
    "    equalized = cv2.equalizeHist(img_gry)\n",
    "\n",
    "    # Apply Gaussian blurring\n",
    "    img_blur = cv2.GaussianBlur(equalized, (5,5), 0) \n",
    "\n",
    "    # Apply Otsubin thresholding\n",
    "    ret, img_Otsubin = cv2.threshold(img_gry,10,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    imagetocanny = img_Otsubin\n",
    "\n",
    "    edges = cv2.Canny(image=imagetocanny, threshold1=200, threshold2=200) # Canny Edge Detection\n",
    "\n",
    "\n",
    "    '''\n",
    "    rho = 1  # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "    threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 100  # minimum number of pixels making up a line\n",
    "    max_line_gap = 30  # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(img_Otsubin) * 0  # creating a blank to draw lines on\n",
    "    '''\n",
    "\n",
    "    line_image = np.copy(img_Otsubin) * 0  # creating a blank to draw lines on\n",
    "\n",
    "    # Run Hough on edge detected image. Output lines are an array containing endpoints of detected line segments\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/100, 15, np.array([]),\n",
    "                        100, 30)\n",
    "\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(image,(x1,y1),(x2,y2),(255,0,0),5)\n",
    "            cv2.line(whiteboard,(x1,y1),(x2,y2),(255,0,0),5)\n",
    "\n",
    "    result = []\n",
    "    # Left line\n",
    "    y1 = y - 1\n",
    "    x1 = halfx\n",
    "    while x1 > 0:\n",
    "        pixel_color = whiteboard[y1, x1]  # OpenCV uses (row, column) indexing\n",
    "\n",
    "        # Assuming OpenCV uses BGR format for color representation\n",
    "        if all(pixel_color == [255, 0, 0]):  # Checking for blue color (assuming BGR values)\n",
    "            # If you want to stop at the first blue pixel, you can break here\n",
    "            break\n",
    "        # Move up one pixel on the line\n",
    "        y1 -= 1\n",
    "        x1 -= 1\n",
    "    cv2.line(image,(x1,y1),(halfx,y),(0,255,0),5)\n",
    "    result.append(int(math.hypot(halfx - x1, yless - y1)))\n",
    "\n",
    "    # Center line\n",
    "    y2 = yless\n",
    "    x2 = halfx\n",
    "    while y2 > 0:\n",
    "        pixel_color = whiteboard[y2, x2]  # OpenCV uses (row, column) indexing\n",
    "\n",
    "        # Assuming OpenCV uses BGR format for color representation\n",
    "        if all(pixel_color == [255, 0, 0]):  # Checking for blue color (assuming BGR values)\n",
    "\n",
    "            # If you want to stop at the first blue pixel, you can break here\n",
    "            break\n",
    "        # Move up one pixel on the line\n",
    "        y2 -= 1\n",
    "    cv2.line(image,(halfx,y2),(halfx,y),(0,255,0),5)\n",
    "\n",
    "    result.append(int(math.hypot(halfx - x2, 719 - y2)))\n",
    "\n",
    "    # Right line\n",
    "    y3 = yless\n",
    "    x3 = halfx\n",
    "    while x3 < x:\n",
    "        pixel_color = whiteboard[y3, x3]  # OpenCV uses (row, column) indexing\n",
    "\n",
    "        # Assuming OpenCV uses BGR format for color representation\n",
    "        if all(pixel_color == [255, 0, 0]):  # Checking for blue color (assuming BGR values)\n",
    "            # If you want to stop at the first blue pixel, you can break here\n",
    "            break\n",
    "        # Move up one pixel on the line\n",
    "        y3 -= 1\n",
    "        x3 += 1\n",
    "    cv2.line(image,(x3,y3),(halfx,y),(0,255,0),5)\n",
    "\n",
    "    result.append(int(math.hypot(halfx - x3, 719 - y3)))\n",
    "    print(result)\n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('frame', image) \n",
    "      \n",
    "    # the 'q' button is set as the \n",
    "    # quitting button you may use any \n",
    "    # desired button of your choice \n",
    "    if cv2.waitKey(1) == ord('q'): \n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object \n",
    "vid.release()\n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture(2) \n",
    "while(True): \n",
    "    ret, image = vid.read()\n",
    "    cv2.imshow('frame', image) \n",
    "    print(image.shape[1])\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "# After the loop release the cap object \n",
    "vid.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_image = np.ones((1080, 1920, 3), np.uint8) * 256 \n",
    "plt.imshow(cv2.cvtColor(white_image, cv2.COLOR_BGR2RGB))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
